import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import time
import unicodedata
from datetime import datetime
import openai
import anthropic
import google.generativeai as genai
from typing import List, Dict, Tuple

# Konfigurace str√°nky
st.set_page_config(
    page_title="AI Verification Tool",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS pro lep≈°√≠ vzhled
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
        margin: 1rem 0;
    }
    .success-card {
        background: #d4edda;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .error-card {
        background: #f8d7da;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #dc3545;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Hlaviƒçku aplikace
st.markdown("""
<div class="main-header">
    <h1>üîç AI Verification Tool</h1>
    <p>Ovƒõ≈ôen√≠ zobrazen√≠ znaƒçky v AI - Komplexn√≠ anal√Ωza</p>
</div>
""", unsafe_allow_html=True)

# Sidebar s n√°vodem
with st.sidebar:
    st.header("üìã N√°vod pou≈æit√≠")
    st.markdown("""
    1. **Zadejte √∫daje** o znaƒçce a dom√©nƒõ
    2. **Kliknƒõte** na "Spustit anal√Ωzu"  
    3. **Poƒçkejte** na dokonƒçen√≠ (nƒõkolik minut)
    4. **Prohl√©dnƒõte** si v√Ωsledky
    5. **St√°hnƒõte** data jako CSV
    """)
    
    st.markdown("---")
    st.info("üîß API kl√≠ƒçe jsou p≈ôedkonfigurov√°ny")

# Hlavn√≠ formul√°≈ô
col1, col2 = st.columns(2)

with col1:
    brand = st.text_input("üè∑Ô∏è Brand", value="taste", help="N√°zev znaƒçky k hled√°n√≠")
    domena = st.text_input("üåê Dom√©na", value="taste.cz", help="Webov√° dom√©na (bez https://)")

with col2:
    zeme = st.selectbox(
        "üåç Zemƒõ",
        ["ƒåesk√° republika", "Slovensko", "Polsko", "Nƒõmecko", "Rakousko", "Maƒèarsko"],
        help="Zemƒõ pro doporuƒçen√≠ spoleƒçnost√≠"
    )

# Funkce pro web scraping
def scrape_website(domain: str) -> str:
    """St√°hne a zpracuje obsah webov√© str√°nky"""
    urls_to_try = [f"https://{domain}", f"http://{domain}"]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    for url in urls_to_try:
        try:
            response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Odstranƒõn√≠ nepot≈ôebn√Ωch element≈Ø
                for script in soup(["script", "style", "nav", "footer", "header"]):
                    script.decompose()
                
                # Extrakce textu
                text = soup.get_text(separator='\n', strip=True)
                text = re.sub(r'\s+', ' ', text)
                text = re.sub(r'\n+', '\n', text)
                
                # Omezen√≠ d√©lky
                MAX_LENGTH = 15000
                if len(text) > MAX_LENGTH:
                    text = text[:MAX_LENGTH] + "... (text byl zkr√°cen)"
                
                return text
                
        except Exception as e:
            st.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ {url}: {str(e)}")
            continue
    
    return f"CHYBA: Nepoda≈ôilo se naƒç√≠st str√°nku {domain}"

# AI API funkce
def query_openai(prompt: str, api_key: str) -> str:
    """Dotaz na OpenAI ChatGPT"""
    try:
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=2048
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"‚ùå Chyba: {str(e)}"

def query_claude(prompt: str, api_key: str) -> str:
    """Dotaz na Claude AI"""
    try:
        client = anthropic.Anthropic(api_key=api_key)
        response = client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=2048,
            temperature=0.7,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    except Exception as e:
        return f"‚ùå Chyba: {str(e)}"

def query_gemini(prompt: str, api_key: str) -> str:
    """Dotaz na Google Gemini"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"‚ùå Chyba: {str(e)}"

def extract_business_areas(content: str, api_key: str) -> List[str]:
    """Extrakce oblast√≠ podnik√°n√≠ z obsahu webu pomoc√≠ AI"""
    prompt = f"""Analyzuj n√°sleduj√≠c√≠ text z webov√© str√°nky a identifikuj maxim√°lnƒõ 5 kl√≠ƒçov√Ωch oblast√≠ podnik√°n√≠ nebo t√©mat, kter√Ωm se tato str√°nka/spoleƒçnost vƒõnuje. Ka≈ædou oblast uveƒè na nov√Ω ≈ô√°dek. Pokud nelze identifikovat ≈æ√°dn√© smyslupln√© oblasti, odpovƒõz "Nebylo mo≈æn√© identifikovat oblasti".

Text:
{content}"""
    
    response = query_gemini(prompt, api_key)
    
    if "‚ùå Chyba:" in response:
        return [f"Chyba AI p≈ôi generov√°n√≠ oblast√≠: {response}"]
    
    if "nebylo mo≈æn√© identifikovat" in response.lower():
        return ["Nebylo mo≈æn√© identifikovat oblasti z textu"]
    
    areas = [area.strip() for area in response.split('\n') if area.strip()]
    return areas[:5]  # Maxim√°lnƒõ 5 oblast√≠

def intelligent_check(text: str, search_term: str) -> str:
    """Inteligentn√≠ kontrola v√Ωskytu term√≠nu v textu"""
    if not text or not search_term:
        return "N/A"
    
    # Normalizace textu (odstranƒõn√≠ diakritiky)
    normalized_text = unicodedata.normalize('NFD', text.lower())
    normalized_text = ''.join(c for c in normalized_text if unicodedata.category(c) != 'Mn')
    
    normalized_search = unicodedata.normalize('NFD', search_term.lower())
    normalized_search = ''.join(c for c in normalized_search if unicodedata.category(c) != 'Mn')
    
    return "‚úÖ Ano" if normalized_search in normalized_text else "‚ùå Ne"

# Naƒçten√≠ API kl√≠ƒç≈Ø ze secrets
try:
    openai_key = st.secrets["api_keys"]["openai"]
    anthropic_key = st.secrets["api_keys"]["anthropic"] 
    gemini_key = st.secrets["api_keys"]["gemini"]
except KeyError as e:
    st.error(f"‚ùå Chybƒõj√≠c√≠ API kl√≠ƒç v konfiguraci: {e}")
    st.stop()

# Hlavn√≠ spou≈°tƒõc√≠ tlaƒç√≠tko
if st.button("üöÄ Spustit anal√Ωzu", type="primary", use_container_width=True):
    
    if not domena:
        st.error("‚ö†Ô∏è Vypl≈àte pros√≠m dom√©nu!")
        st.stop()
    
    # Inicializace session state pro v√Ωsledky
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {}
    
    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Krok 1: Web scraping
    status_text.markdown('<div class="status-card">üï∏Ô∏è <strong>Krok 1/4:</strong> Stahuji obsah webu...</div>', unsafe_allow_html=True)
    progress_bar.progress(10)
    
    website_content = scrape_website(domena)
    
    if website_content.startswith("CHYBA:"):
        st.markdown(f'<div class="error-card">{website_content}</div>', unsafe_allow_html=True)
        st.stop()
    
    # Krok 2: Extrakce oblast√≠
    status_text.markdown('<div class="status-card">üß† <strong>Krok 2/4:</strong> Analyzuji oblasti podnik√°n√≠...</div>', unsafe_allow_html=True)
    progress_bar.progress(25)
    
    business_areas = extract_business_areas(website_content, gemini_key)
    
    if not business_areas or (len(business_areas) == 1 and ("Chyba" in business_areas[0] or "nebylo mo≈æn√©" in business_areas[0].lower())):
        st.markdown('<div class="error-card">‚ùå Nepoda≈ôilo se identifikovat oblasti podnik√°n√≠</div>', unsafe_allow_html=True)
        st.write("Extrahovan√© oblasti:", business_areas)
        st.stop()
    
    st.markdown('<div class="success-card">‚úÖ <strong>Identifikovan√© oblasti:</strong><br>' + '<br>'.join([f"‚Ä¢ {area}" for area in business_areas]) + '</div>', unsafe_allow_html=True)
    
    # Krok 3: Dotazov√°n√≠ AI model≈Ø
    status_text.markdown('<div class="status-card">ü§ñ <strong>Krok 3/4:</strong> Dotazuji AI modely...</div>', unsafe_allow_html=True)
    
    all_responses = []
    analysis_results = []
    
    total_queries = len(business_areas) * 3
    current_query = 0
    
    for area in business_areas:
        clean_area = area.strip()
        if not clean_area or "Chyba" in clean_area or "nebylo mo≈æn√©" in clean_area.lower():
            continue
        
        query = f'Jak√© spoleƒçnosti z oblasti "{clean_area}" doporuƒçuje≈° v zemi "{zeme}"?'
        
        # ChatGPT
        current_query += 1
        progress_bar.progress(25 + (current_query / total_queries) * 50)
        status_text.markdown(f'<div class="status-card">ü§ñ Dotazuji ChatGPT ({current_query}/{total_queries})...</div>', unsafe_allow_html=True)
        
        gpt_response = query_openai(query, openai_key)
        all_responses.append({
            "Dotaz + AI": f"{query} (ChatGPT)",
            "Odpovƒõƒè AI": gpt_response
        })
        
        # Claude AI
        current_query += 1
        progress_bar.progress(25 + (current_query / total_queries) * 50)
        status_text.markdown(f'<div class="status-card">üß† Dotazuji Claude AI ({current_query}/{total_queries})...</div>', unsafe_allow_html=True)
        
        claude_response = query_claude(query, anthropic_key)
        all_responses.append({
            "Dotaz + AI": f"{query} (Claude AI)",
            "Odpovƒõƒè AI": claude_response
        })
        
        # Gemini
        current_query += 1
        progress_bar.progress(25 + (current_query / total_queries) * 50)
        status_text.markdown(f'<div class="status-card">‚ú® Dotazuji Gemini ({current_query}/{total_queries})...</div>', unsafe_allow_html=True)
        
        gemini_response = query_gemini(query, gemini_key)
        all_responses.append({
            "Dotaz + AI": f"{query} (Gemini)",
            "Odpovƒõƒè AI": gemini_response
        })
        
        # Anal√Ωza zm√≠nek pro ka≈æd√© AI
        for ai_name, response in [("ChatGPT", gpt_response), ("Claude AI", claude_response), ("Gemini", gemini_response)]:
            brand_match = intelligent_check(response, brand)
            domain_match = intelligent_check(response, domena)
            
            analysis_results.append({
                "Oblast": clean_area,
                "AI": ai_name,
                "Brand": brand_match,
                "Dom√©na": domain_match
            })
        
        time.sleep(1)  # Rate limiting
    
    # Krok 4: Finalizace
    status_text.markdown('<div class="status-card">üìä <strong>Krok 4/4:</strong> Finalizuji v√Ωsledky...</div>', unsafe_allow_html=True)
    progress_bar.progress(100)
    
    # Ulo≈æen√≠ do session state
    st.session_state.analysis_results = {
        'responses': all_responses,
        'analysis': analysis_results,
        'metadata': {
            'brand': brand,
            'domain': domena,
            'country': zeme,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'areas_found': len(business_areas)
        }
    }
    
    status_text.markdown('<div class="success-card">‚úÖ <strong>Anal√Ωza dokonƒçena!</strong></div>', unsafe_allow_html=True)
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()

# Zobrazen√≠ v√Ωsledk≈Ø (pokud existuj√≠)
if 'analysis_results' in st.session_state and st.session_state.analysis_results:
    results = st.session_state.analysis_results
    
    st.markdown("---")
    st.header("üìä V√Ωsledky anal√Ωzy")
    
    # Metadata
    metadata = results['metadata']
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Brand", metadata['brand'])
    with col2:
        st.metric("Dom√©na", metadata['domain'])
    with col3:
        st.metric("Zemƒõ", metadata['country'])
    with col4:
        st.metric("Nalezen√© oblasti", metadata['areas_found'])
    
    # Tabs pro v√Ωsledky
    tab1, tab2, tab3 = st.tabs(["üìã Souhrn odpovƒõd√≠ AI", "üìä Anal√Ωza zm√≠nek", "üìà Statistiky"])
    
    with tab1:
        st.subheader("V≈°echny odpovƒõdi AI model≈Ø")
        responses_df = pd.DataFrame(results['responses'])
        st.dataframe(responses_df, use_container_width=True, height=600)
        
        # CSV download pro odpovƒõdi
        csv_responses = responses_df.to_csv(index=False, encoding='utf-8')
        st.download_button(
            label="üíæ St√°hnout odpovƒõdi jako CSV",
            data=csv_responses,
            file_name=f"ai_responses_{metadata['brand']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with tab2:
        st.subheader("Anal√Ωza zm√≠nek znaƒçky a dom√©ny")
        analysis_df = pd.DataFrame(results['analysis'])
        
        # Barevn√© form√°tov√°n√≠
        def highlight_results(val):
            if val == "‚úÖ Ano":
                return 'background-color: #d4edda; color: #155724'
            elif val == "‚ùå Ne":
                return 'background-color: #f8d7da; color: #721c24'
            return ''
        
        styled_df = analysis_df.style.applymap(highlight_results, subset=['Brand', 'Dom√©na'])
        st.dataframe(styled_df, use_container_width=True)
        
        # CSV download pro anal√Ωzu
        csv_analysis = analysis_df.to_csv(index=False, encoding='utf-8')
        st.download_button(
            label="üíæ St√°hnout anal√Ωzu jako CSV",
            data=csv_analysis,
            file_name=f"ai_analysis_{metadata['brand']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with tab3:
        st.subheader("Statistiky zm√≠nek")
        
        # Statistiky pro brand
        brand_stats = analysis_df['Brand'].value_counts()
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Zm√≠nky brandu:**")
            if "‚úÖ Ano" in brand_stats:
                st.success(f"‚úÖ Zm√≠nƒõn: {brand_stats['‚úÖ Ano']}x")
            if "‚ùå Ne" in brand_stats:
                st.error(f"‚ùå Nezm√≠nƒõn: {brand_stats['‚ùå Ne']}x")
        
        with col2:
            st.write("**Zm√≠nky dom√©ny:**")
            domain_stats = analysis_df['Dom√©na'].value_counts()
            if "‚úÖ Ano" in domain_stats:
                st.success(f"‚úÖ Zm√≠nƒõna: {domain_stats['‚úÖ Ano']}x")
            if "‚ùå Ne" in domain_stats:
                st.error(f"‚ùå Nezm√≠nƒõna: {domain_stats['‚ùå Ne']}x")
        
        # Statistiky po AI
        st.write("**√öspƒõ≈°nost podle AI model≈Ø:**")
        ai_stats = analysis_df.groupby('AI').agg({
            'Brand': lambda x: (x == "‚úÖ Ano").sum(),
            'Dom√©na': lambda x: (x == "‚úÖ Ano").sum()
        })
        ai_stats.columns = ['Brand zm√≠nky', 'Dom√©na zm√≠nky']
        st.dataframe(ai_stats)



# Footer
st.markdown("---")
st.markdown("*üîç AI Verification Tool - Vytvo≈ôeno pro anal√Ωzu zm√≠nek znaƒçky v AI odpovƒõd√≠ch*")
